{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動かなかった　未完成\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv = pd.read_csv(\"CSV/ref.csv\")\n",
    "df = pd.DataFrame(csv[\"USD\"])\n",
    "df\n",
    "\n",
    "k = 0\n",
    "for p in range(15): \n",
    "    for i in range(25):\n",
    "        X_train,y_train =df[k + i]\n",
    "# モデルの作成\n",
    "    model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    history = model.fit(X_train, y_train, epochs=20,\n",
    "    validation_data=(X_valid, y_valid))\n",
    "    model.evaluate(X_valid, y_valid)\n",
    "\n",
    "\n",
    "    # グラフの表示\n",
    "    def plot_series(series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\", legend=True):\n",
    "        plt.plot(series, \".-\")\n",
    "        if y is not None:\n",
    "            plt.plot(n_steps, y, \"bo\", label=\"Target\")\n",
    "        if y_pred is not None:\n",
    "            plt.plot(n_steps, y_pred, \"rx\", markersize=10, label=\"Prediction\")\n",
    "            plt.grid(True)\n",
    "        if x_label:\n",
    "            plt.xlabel(x_label, fontsize=16)\n",
    "        if y_label:\n",
    "            plt.ylabel(y_label, fontsize=16, rotation=0)\n",
    "            plt.hlines(0, 0, 100, linewidth=1)\n",
    "            plt.axis([0, n_steps + 1, -1, 1])\n",
    "        if legend and (y or y_pred):\n",
    "            plt.legend(fontsize=14, loc=\"upper left\")\n",
    "    y_pred = model.predict(X_valid)\n",
    "    plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])\n",
    "    plt.show()\n",
    "    k = k +25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "test_size=1000 should be either positive and smaller than the number of samples 1 or a float in the (0, 1) range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mセル2 を d:\\anaconda3\\program_files\\tensorflow_3.ipynb\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/anaconda3/program_files/tensorflow_3.ipynb#ch0000001?line=29'>30</a>\u001b[0m X, y \u001b[39m=\u001b[39m make_dataset(x_scaled, \u001b[39m25\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/anaconda3/program_files/tensorflow_3.ipynb#ch0000001?line=31'>32</a>\u001b[0m \u001b[39m# 訓練セットと評価セットの作成\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/anaconda3/program_files/tensorflow_3.ipynb#ch0000001?line=32'>33</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m temporal_train_test_split( X, y, test_size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/anaconda3/program_files/tensorflow_3.ipynb#ch0000001?line=33'>34</a>\u001b[0m X_train, X_valid, y_train, y_valid \u001b[39m=\u001b[39m temporal_train_test_split( X, y, test_size\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/anaconda3/program_files/tensorflow_3.ipynb#ch0000001?line=34'>35</a>\u001b[0m \u001b[39m# X_train ,X_test, X_valid = temporal_train_test_split(X,test_size=0.1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/anaconda3/program_files/tensorflow_3.ipynb#ch0000001?line=35'>36</a>\u001b[0m \u001b[39m# y_train,y_test,y_valid = temporal_train_test_split(y,test_size= 0.1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/anaconda3/program_files/tensorflow_3.ipynb#ch0000001?line=36'>37</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/anaconda3/program_files/tensorflow_3.ipynb#ch0000001?line=37'>38</a>\u001b[0m \u001b[39m# 学習モデルの生成\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\sktime\\forecasting\\model_selection\\_split.py:1365\u001b[0m, in \u001b[0;36mtemporal_train_test_split\u001b[1;34m(y, X, test_size, train_size, fh)\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1364\u001b[0m     series \u001b[39m=\u001b[39m (y,) \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (y, X)\n\u001b[1;32m-> 1365\u001b[0m     \u001b[39mreturn\u001b[39;00m _train_test_split(\n\u001b[0;32m   1366\u001b[0m         \u001b[39m*\u001b[39;49mseries,\n\u001b[0;32m   1367\u001b[0m         shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1368\u001b[0m         stratify\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1369\u001b[0m         test_size\u001b[39m=\u001b[39;49mtest_size,\n\u001b[0;32m   1370\u001b[0m         train_size\u001b[39m=\u001b[39;49mtrain_size,\n\u001b[0;32m   1371\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2420\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2417\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[0;32m   2419\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m-> 2420\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2421\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[0;32m   2422\u001b[0m )\n\u001b[0;32m   2424\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m   2425\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2043\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2035\u001b[0m train_size_type \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(train_size)\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind\n\u001b[0;32m   2037\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2038\u001b[0m     test_size_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2039\u001b[0m     \u001b[39mand\u001b[39;00m (test_size \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m n_samples \u001b[39mor\u001b[39;00m test_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m   2040\u001b[0m     \u001b[39mor\u001b[39;00m test_size_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2041\u001b[0m     \u001b[39mand\u001b[39;00m (test_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m test_size \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m   2042\u001b[0m ):\n\u001b[1;32m-> 2043\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2044\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtest_size=\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m should be either positive and smaller\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2045\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m than the number of samples \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m or a float in the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2046\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(0, 1) range\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(test_size, n_samples)\n\u001b[0;32m   2047\u001b[0m     )\n\u001b[0;32m   2049\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2050\u001b[0m     train_size_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2051\u001b[0m     \u001b[39mand\u001b[39;00m (train_size \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m n_samples \u001b[39mor\u001b[39;00m train_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m   2052\u001b[0m     \u001b[39mor\u001b[39;00m train_size_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2053\u001b[0m     \u001b[39mand\u001b[39;00m (train_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m train_size \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m   2054\u001b[0m ):\n\u001b[0;32m   2055\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2056\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrain_size=\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m should be either positive and smaller\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2057\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m than the number of samples \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m or a float in the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2058\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(0, 1) range\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(train_size, n_samples)\n\u001b[0;32m   2059\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: test_size=1000 should be either positive and smaller than the number of samples 1 or a float in the (0, 1) range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# データロード\n",
    "df = pd.read_csv(\"CSV/ref.csv\")\n",
    "x = df[\"USD\"].values\n",
    "\n",
    "# スケーリング変換\n",
    "x = x.reshape(-1,1)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "x_scaled = scaler.transform(x)\n",
    "\n",
    "# 目的変数と説明変数の作成\n",
    "def make_dataset( indata, timestep ):\n",
    "    data, target = [], []\n",
    "    for i in range(len(indata)-timestep):\n",
    "        data.append(indata[i:i + timestep])\n",
    "        target.append(indata[i + timestep])\n",
    "        re_data = np.array(data).reshape(len(data), timestep, 1)\n",
    "        re_target = np.array(target).reshape(len(data), 1)\n",
    "        return re_data, re_target\n",
    "\n",
    "X, y = make_dataset(x_scaled, 25)\n",
    "\n",
    "# 訓練セットと評価セットの作成\n",
    "X_train, X_test, y_train, y_test = temporal_train_test_split( X, y, test_size=1000 )\n",
    "X_train, X_valid, y_train, y_valid = temporal_train_test_split( X, y, test_size=1000 )\n",
    "# X_train ,X_test, X_valid = temporal_train_test_split(X,test_size=0.1)\n",
    "# y_train,y_test,y_valid = temporal_train_test_split(y,test_size= 0.1)\n",
    "\n",
    "# 学習モデルの生成\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "model = keras.models.Sequential([\n",
    "keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "keras.layers.SimpleRNN(20),\n",
    "keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# 評価\n",
    "model.evaluate(X_valid, y_valid)\n",
    "pred = model.predict(X_test)\n",
    "pred_train = model.predict(X_train)\n",
    "print(\"Test data R2 score: %.4f\" % (r2_score(y_valid.flatten(), pred.flatten())))\n",
    "print(\"Train data R2 score: %.4f\" % (r2_score(y_train.flatten(), pred_train.flatten())))\n",
    "\n",
    "# 学習曲線\n",
    "plt.plot(history.history['loss'],label=\"train set\")\n",
    "plt.plot(history.history['val_loss'],label=\"test set\")\n",
    "plt.title('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 予測結果\n",
    "plt.plot(y_valid,label=\"y\")\n",
    "plt.plot(pred,label=\"pred\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cb49aa8c70483ec86efb95e50ae759e64488101622f1c32f44ab1d8fac2e871"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
